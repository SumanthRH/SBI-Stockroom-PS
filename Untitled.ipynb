{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation,Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Lambda, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block3a(I):\n",
    "    X_3x3 = Conv2D(96, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(128, (3, 3))(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(16, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(32, (5, 5))(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(32, (1, 1))(X_pool)\n",
    "    X_pool = BatchNormalization(axis=1, epsilon=0.00001)(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding=7)(X_pool) # need a check\n",
    "\n",
    "    X_1x1 = Conv2D(64, (1, 1))(I)\n",
    "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001)(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=-1)\n",
    "\n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block3b(I) :\n",
    "    X_3x3 = Conv2D(96, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(128, (3, 3))(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(32, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(64, (5, 5))(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(64, (1, 1))(X_pool)\n",
    "    X_pool = BatchNormalization(axis=1, epsilon=0.00001)(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding=7)(X_pool) # check\n",
    "\n",
    "    X_1x1 = Conv2D(64, (1, 1))(I)\n",
    "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001)(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=-1)\n",
    "  \n",
    "    return inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block3c(I) :\n",
    "    X_3x3 = Conv2D(128, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(256, (3, 3),strides=2)(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(32, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(64, (5, 5),strides=2)(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = ZeroPadding2D(padding=((1,0),(1,0)))(X_pool) #assymmetric padding- check\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=-1)\n",
    "  \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block4a(I):\n",
    "    X_3x3 = Conv2D(96, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(192, (3, 3))(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(32, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(64, (5, 5))(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "#L2 here\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(128,(1,1))(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding =4)(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "                          \n",
    "    X_1x1 = Conv2D(256, (1, 1))(I)\n",
    "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001)(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=-1)\n",
    "                          \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block4b(I):\n",
    "    X_3x3 = Conv2D(112, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(224, (3, 3))(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(32, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(64, (5, 5))(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "#L2 here\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(128,(1,1))(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding =4)(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "                          \n",
    "    X_1x1 = Conv2D(224, (1, 1))(I)\n",
    "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001)(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=-1)\n",
    "                          \n",
    "    return inception\n",
    "# need to add two more blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block4e(I):\n",
    "    X_3x3 = Conv2D(160, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(256,(3, 3),strides=2)(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(64, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(128, (5, 5),strides=2)(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(128,(1,1))(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding =((1,0),(1,0)))(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "    \n",
    "    \n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=-1)\n",
    "                          \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block5a(I):\n",
    "    X_3x3 = Conv2D(192, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(384,(3, 3))(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(48, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(128, (5, 5))(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "#L2 here\n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(128,(1,1))(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding =2)(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "    \n",
    "    X_1x1 = Conv2D(384, (1, 1))(I)\n",
    "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001)(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool,X_1x1], axis=-1)\n",
    "                          \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block5b(I):\n",
    "    X_3x3 = Conv2D(192, (1, 1))(I)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding=(1, 1))(X_3x3)\n",
    "    X_3x3 = Conv2D(384,(3, 3))(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001)(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(48, (1, 1))(I)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding=(2, 2))(X_5x5)\n",
    "    X_5x5 = Conv2D(128, (5, 5))(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001)(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    \n",
    "    X_pool = MaxPooling2D(pool_size=(3, 3), strides=2)(I)\n",
    "    X_pool = Conv2D(128,(1,1))(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding =2)(X_pool)\n",
    "    X_pool = Activation('relu')(X_pool)\n",
    "    \n",
    "    X_1x1 = Conv2D(384, (1, 1))(I)\n",
    "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001)(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool,X_1x1], axis=-1)\n",
    "                          \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnmodel(input_shape):\n",
    "    I=Input(input_shape)\n",
    "    #defining initial blocks now \n",
    "    X=Conv2D(64,(7,7),strides=2,padding=\"same\",activation=\"relu\",input_shape=(224,224,3))(I)\n",
    "    X=ZeroPadding2D((1,1))(X)\n",
    "    X=MaxPooling2D((3,3),strides=2)(X)\n",
    "    X=BatchNormalization(axis=1, epsilon=0.00001)(X)\n",
    "   \n",
    "    X=Conv2D(64,(1,1),activation=\"relu\",input_shape=(56,56,64))(X)\n",
    "    X=Conv2D(192,(3,3),activation=\"relu\")(X)\n",
    "    X=BatchNormalization(axis=1, epsilon=0.00001)(X)\n",
    "    X=ZeroPadding2D((1,1))(X)\n",
    "    X=MaxPooling2D((3,3),strides=2)(X)\n",
    "    \n",
    "    X=inception_block3a(X)\n",
    "    X=inception_block3b(X)\n",
    "    X=inception_block3c(X)\n",
    "    \n",
    "    X=inception_block4a(X)\n",
    "    X=inception_block4b(X)\n",
    "    X=inception_block4e(X)\n",
    "    \n",
    "    X=inception_block5a(X)\n",
    "    X=inception_block5b(X)\n",
    "    \n",
    "    X=AveragePooling2D((3,3))(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(128)(X)\n",
    "    X=Lambda(lambda x: K.l2_normalize(x,axis=1))(X)\n",
    "    \n",
    "    facenet=Model(inputs=I,outputs=X,name=\"facenet\")\n",
    "    return facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripletloss(anchor,positive,negative,margin):\n",
    "\n",
    "    d_pos = K.sum(K.square(anchor - positive), -1)\n",
    "    d_neg = K.sum(K.square(anchor - negative), -1)\n",
    "\n",
    "    loss = K.maximum(0., margin + d_pos - d_neg)\n",
    "    loss = K.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =fnmodel((224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tripletloss() missing 2 required positional arguments: 'negative' and 'margin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-8e488d9c0027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtripletloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 830\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tripletloss() missing 2 required positional arguments: 'negative' and 'margin'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",loss=tripletloss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
